{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INTRO5.DXR', 'MINA02.DXR', 'NIVEL5.DXR', 'CANTERA.DXR', 'INTRO4.DXR', 'FINAL.DXR', 'CABAÃ‘A.DXR', 'INTRO1.DXR', 'CASA.DXR', 'BIBLIO.DXR', 'LABO.DXR', 'NIVEL2.DXR', 'NIVEL-1.DXR', 'MINA01.DXR', 'NIVEL3.DXR', 'NIVEL1.DXR', 'JULIUS.DXR', 'MICROSCOPIO.CXT', 'PRINCIPAL.DXR', 'OPCIONES.DXR', 'INTRO2.DXR', 'MENU.DXR', 'FUERA.DXR', 'MINA03.DXR', 'NIVEL0.DXR', 'AYUDA.DXR', 'INTRO3.DXR', 'GRANDES.CXT', 'FILON.DXR', 'NIVEL4.DXR', 'MADRIG.DXR', 'CUADERNO.DXR', 'PUEBLO.DXR']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import struct\n",
    "import os\n",
    "\n",
    "original_files = os.listdir(\"Archivos\")\n",
    "original_dxr_files = [f for f in original_files if (f.endswith(\".DXR\") or f.endswith(\".CXT\"))]\n",
    "print(original_dxr_files)\n",
    "\n",
    "os.system(\"rm SONIDOS/*.mp3\")\n",
    "os.system(\"rm IMAGENES/*.BITD\")\n",
    "os.system(\"rm IMAGENES/*.PROP\")\n",
    "os.system(\"rm IMAGENES/*.bmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Reading the header =====\n",
      "Header: XFIR\n",
      "File size: 15564738 Bytes\n",
      "File type: 39VM\n"
     ]
    }
   ],
   "source": [
    "# ===== READING THE HEADER =====\n",
    "\n",
    "print(\"===== Reading the header =====\")\n",
    "\n",
    "# opening the target file...\n",
    "file = open(\"Archivos/MINA02.DXR\", \"rb\")\n",
    "\n",
    "# reading the header...\n",
    "file_header = file.read(4).decode('ascii') # always XFIR\n",
    "print(\"Header: \" + file_header)\n",
    "\n",
    "# reading the file size\n",
    "file_size, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"File size: \" + str(file_size) + \" Bytes\")\n",
    "\n",
    "# reading the file type\n",
    "file_type = file.read(4).decode('ascii')\n",
    "print(\"File type: \" + file_type) # always 39VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Reading the initial map =====\n",
      "imap header: pami\n",
      "imap size: 24 Bytes\n",
      "mmap count: 1\n",
      "mmap offset: 44\n",
      "mmap version: 1406\n"
     ]
    }
   ],
   "source": [
    "# ===== READING THE INITIAL MAP =====\n",
    "\n",
    "print(\"===== Reading the initial map =====\")\n",
    "\n",
    "# reading imap's header\n",
    "imap_header = file.read(4).decode('ascii')\n",
    "print(\"imap header: \" + imap_header) # always pami\n",
    "\n",
    "# reading imap's size\n",
    "imap_size, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"imap size: \" + str(imap_size) + \" Bytes\")\n",
    "\n",
    "# reading the number of mmap's\n",
    "mmap_count, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"mmap count: \" + str(mmap_count)) # hopefully always 1\n",
    "\n",
    "# reading mmap's offset\n",
    "mmap_offset, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"mmap offset: \" + str(mmap_offset))\n",
    "\n",
    "# reading mmap's version\n",
    "mmap_version, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"mmap version: \" + str(mmap_version)) # hopefully useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Reading the memory map =====\n",
      "mmap header: pamm\n",
      "mmap size: 232484 Bytes\n",
      "mmap properties size: 24 Bytes\n",
      "mmap resource entry size: 20 Bytes\n",
      "mmap max resource count: 11623\n",
      "mmap resource count: 10766\n",
      "mmap last junk resource id: 10757\n",
      "mmap old mmap resource id: 4294967295\n",
      "mmap unknown: 9788\n",
      "Loading resource table of contents...\n",
      "Resource table of contents loaded.\n"
     ]
    }
   ],
   "source": [
    "# ===== READING THE MEMORY MAP =====\n",
    "\n",
    "print(\"===== Reading the memory map =====\")\n",
    "\n",
    "# pointing to the memory map thanks to previous data\n",
    "file.seek(mmap_offset, 0)\n",
    "\n",
    "# reading mmap's header\n",
    "mmap_header = file.read(4).decode('ascii')\n",
    "print(\"mmap header: \" + mmap_header)\n",
    "\n",
    "# reading mmap's size\n",
    "mmap_size, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"mmap size: \" + str(mmap_size) + \" Bytes\")\n",
    "\n",
    "# reading mmap's properties size\n",
    "mmap_prop_size, = struct.unpack(\"<H\", file.read(2))\n",
    "print(\"mmap properties size: \" + str(mmap_prop_size) + \" Bytes\")\n",
    "\n",
    "# reading the size of each resource entry in the mmap\n",
    "mmap_resource_entry_size, = struct.unpack(\"<H\", file.read(2))\n",
    "print(\"mmap resource entry size: \" + str(mmap_resource_entry_size) + \" Bytes\")\n",
    "\n",
    "# reading the maximum resources that can fit in the mmap\n",
    "mmap_max_resource_count, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"mmap max resource count: \" + str(mmap_max_resource_count))\n",
    "\n",
    "# reading the actual resources in the mmap\n",
    "mmap_resource_count, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"mmap resource count: \" + str(mmap_resource_count))\n",
    "\n",
    "# reading the last junk resource id\n",
    "mmap_last_junk, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"mmap last junk resource id: \" + str(mmap_last_junk)) # hopefully useless\n",
    "\n",
    "# reading the old mmap resource id\n",
    "mmap_old_mmap_id, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"mmap old mmap resource id: \" + str(mmap_old_mmap_id)) # hopefully meaningless\n",
    "\n",
    "# reading into the unknown\n",
    "mmap_unk1, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"mmap unknown: \" + str(mmap_unk1)) # hopefully useless\n",
    "\n",
    "# loading resource entries\n",
    "print(\"Loading resource table of contents...\")\n",
    "resources = []\n",
    "for i in range(0, mmap_resource_count):\n",
    "    tag = file.read(4).decode('ascii')\n",
    "    size, = struct.unpack(\"<I\", file.read(4))\n",
    "    offset, = struct.unpack(\"<i\", file.read(4))\n",
    "    flags, = struct.unpack(\"H\", file.read(2))\n",
    "    unk1, = struct.unpack(\"H\", file.read(2))\n",
    "    next_free_resource_id, = struct.unpack(\"<I\", file.read(4))\n",
    "    resources.append((i,offset,size,tag))\n",
    "print(\"Resource table of contents loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Reading the KEY* =====\n",
      "KEY* header: *YEK\n",
      "KEY* size: 13632 Bytes\n",
      "KEY* properties size: 12 Bytes\n",
      "KEY* entry size: 12 Bytes\n",
      "mmap max resource count: 1135\n",
      "mmap resource count: 783\n",
      "Loading the keys...\n",
      "Keys loaded.\n"
     ]
    }
   ],
   "source": [
    "# ===== READING THE KEY* =====\n",
    "\n",
    "print(\"===== Reading the KEY* =====\")\n",
    "\n",
    "key = resources[3] # it is known to always be the third.\n",
    "\n",
    "# pointing to the KEY* thanks to the resource table of contents\n",
    "file.seek(key[1], 0)\n",
    "\n",
    "# reading KEY*'s header\n",
    "keys_header = file.read(4).decode('ascii')\n",
    "print(\"KEY* header: \" + keys_header) # always *YEK\n",
    "\n",
    "# reading KEY*'s size\n",
    "keys_size, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"KEY* size: \" + str(keys_size) + \" Bytes\")\n",
    "\n",
    "# reading KEY*'s properties size\n",
    "keys_prop_size, = struct.unpack(\"<H\", file.read(2))\n",
    "print(\"KEY* properties size: \" + str(keys_prop_size) + \" Bytes\")\n",
    "\n",
    "# reading the size of each key entry in KEY*\n",
    "keys_entry_size, = struct.unpack(\"<H\", file.read(2))\n",
    "print(\"KEY* entry size: \" + str(keys_entry_size) + \" Bytes\")\n",
    "\n",
    "# reading the maximum keys that can fit in KEY*\n",
    "keys_max, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"mmap max resource count: \" + str(keys_max))\n",
    "\n",
    "# reading the actual keys in KEY*\n",
    "keys_count, = struct.unpack(\"<I\", file.read(4))\n",
    "print(\"mmap resource count: \" + str(keys_count))\n",
    "\n",
    "# loading keys\n",
    "print(\"Loading the keys...\")\n",
    "owned = {}\n",
    "for i in range(0, keys_count):\n",
    "    index_owned, = struct.unpack(\"<I\", file.read(4))\n",
    "    owners_index, = struct.unpack(\"<I\", file.read(4))\n",
    "    owned_chunk_id = file.read(4).decode('ascii')\n",
    "    if owners_index not in owned:\n",
    "        owned[owners_index] = []\n",
    "    owned[owners_index].append((index_owned, owned_chunk_id))\n",
    "print(\"Keys loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Reading the CAS*'s =====\n",
      "Searching for CAS* resources...\n",
      "5 CAS*'s found.\n",
      "CAS* 0 header: *SAC\n",
      "CAS* 0 size: 1624 Bytes\n",
      "CAS* 0 cast members: 406\n",
      "CAS* 1 header: *SAC\n",
      "CAS* 1 size: 236 Bytes\n",
      "CAS* 1 cast members: 59\n",
      "CAS* 2 header: *SAC\n",
      "CAS* 2 size: 244 Bytes\n",
      "CAS* 2 cast members: 61\n",
      "CAS* 3 header: *SAC\n",
      "CAS* 3 size: 192 Bytes\n",
      "CAS* 3 cast members: 48\n",
      "CAS* 4 header: *SAC\n",
      "CAS* 4 size: 548 Bytes\n",
      "CAS* 4 cast members: 137\n"
     ]
    }
   ],
   "source": [
    "# ===== READING THE CAS*'s =====\n",
    "\n",
    "print(\"===== Reading the CAS*'s =====\")\n",
    "\n",
    "# Just brute-force search them in the resource table of contents\n",
    "print(\"Searching for CAS* resources...\")\n",
    "cass = [x for x in resources if x[3] == \"*SAC\"]\n",
    "print(str(len(cass)) + \" CAS*'s found.\")\n",
    "\n",
    "cast_owned = {}\n",
    "\n",
    "for i in range(0, len(cass)):\n",
    "    cast_owned[i] = []\n",
    "    \n",
    "    # pointing to each CAS* thanks to the resource table of contents\n",
    "    file.seek(cass[i][1], 0)\n",
    "    \n",
    "    # reading CAS*'s header\n",
    "    cas_header = file.read(4).decode('ascii')\n",
    "    print(\"CAS* \" + str(i) + \" header: \" + cas_header) # always *SAC\n",
    "    \n",
    "    # reading CAS*'s size\n",
    "    cas_size, = struct.unpack(\"<I\", file.read(4))\n",
    "    print(\"CAS* \" + str(i) + \" size: \" + str(cas_size) + \" Bytes\")\n",
    "    \n",
    "    # computing the total cast members of each cast\n",
    "    cast_members = int(cas_size/4)\n",
    "    print(\"CAS* \" + str(i) + \" cast members: \" + str(cast_members))\n",
    "    \n",
    "    for j in range (0, cast_members):\n",
    "        index, = struct.unpack(\">I\", file.read(4)) # Beware the endianness!\n",
    "        cast_owned[i].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Reading the CastMembers =====\n",
      "Processing CAS* 0...\n",
      "Processing CAS* 1...\n",
      "Processing CAS* 2...\n",
      "Processing CAS* 3...\n",
      "Processing CAS* 4...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# ===== READING THE CASTMEMBERS =====\n",
    "\n",
    "print(\"===== Reading the CastMembers =====\")\n",
    "\n",
    "bitmaps = []\n",
    "sounds = []\n",
    "other = []\n",
    "\n",
    "for i in range(0, len(cass)):\n",
    "    print(\"Processing CAS* \" + str(i) + \"...\")\n",
    "    for j in range(0, len(cast_owned[i])):\n",
    "        castmember_toc = resources[cast_owned[i][j]]\n",
    "        if castmember_toc[3] != 'tSAC':\n",
    "            continue\n",
    "        # pointing to each castmember thanks to the resource toc\n",
    "        file.seek(castmember_toc[1], 0)\n",
    "        file.read(8) # just skip the header and the size (we already know)\n",
    "        \n",
    "        # reading the castmember's type\n",
    "        castmember_type, = struct.unpack(\">I\", file.read(4))\n",
    "        if castmember_type == 1: #Bitmap\n",
    "            # print(str(j) + \": \" + str(castmember_toc) + \" is a bitmap\")\n",
    "            if castmember_toc[0] in owned:\n",
    "                bitmaps.append(castmember_toc[0])\n",
    "                # print(owned[castmember_toc[0]])\n",
    "        elif castmember_type == 6: #Sound\n",
    "            # print(str(j) + \": \" + str(castmember_toc) + \" is a sound\")\n",
    "            if castmember_toc[0] in owned:\n",
    "                sounds.append(castmember_toc[0])\n",
    "                # print(owned[castmember_toc[0]])\n",
    "        else :\n",
    "            other.append(castmember_toc[0])\n",
    "            # print(\"I don't care about \" + str(castmember_toc))\n",
    "\n",
    "print(\"Done.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# ===== READING BITMAPS =====\n",
    "\n",
    "bmp_titles = []\n",
    "\n",
    "# some little icons may give problems because they are in system mac\n",
    "# maybe just discard them all?\n",
    "\n",
    "for i in range(0, len(bitmaps)):\n",
    "    \n",
    "    # pointing to the castmember\n",
    "    file.seek(resources[bitmaps[i]][1],0)\n",
    "    file.read(12) # skipping header, size and type (we already know)\n",
    "    prop1_size, = struct.unpack(\">I\", file.read(4)) # 26 + 9 + name or simply 26\n",
    "    prop2_size, = struct.unpack(\">I\", file.read(4)) # always 28?\n",
    "    if prop1_size == 26:\n",
    "        file.read(26)\n",
    "    else:\n",
    "        file.read(35) # skip useless stuff\n",
    "    if prop1_size-35 >= 0:\n",
    "        bmp_titles.append(str(file.read(prop1_size-35))) #don't decode because of the tildes\n",
    "    else:\n",
    "        bmp_titles.append(\"untitled\"+str(i))\n",
    "    \n",
    "    file.read(2)\n",
    "    p1,p2,q1,q2 = struct.unpack(\">HHHH\", file.read(8))\n",
    "    file.seek(-8,1)\n",
    "    pp1,pp2,qq1,qq2 = struct.unpack(\"<HHHH\", file.read(8))\n",
    "    file.read(1)\n",
    "    file.read(7)\n",
    "    t1,t2=struct.unpack(\">HH\", file.read(4))\n",
    "    file.read(1)\n",
    "    depth, = struct.unpack(\">c\", file.read(1))\n",
    "    depth = ord(depth)\n",
    "    palette, = struct.unpack(\">i\", file.read(4))\n",
    "    if (depth == 0):\n",
    "        palette = -1\n",
    "        depth = 1\n",
    "        #print(bmp_titles[i] + \" \" + str(p1) + \" \" + str(p2) + \" \" + str(q1) + \" \" +str(q2) + \" \" + \" \" +str(depth) + \" \" +str(palette))\n",
    "    w = q2 - p2\n",
    "    h = q1 - p1\n",
    "    \n",
    "    # saving raw bitmaps and properties safely\n",
    "    # print(str(i)+\" \"+bmp_titles[i])\n",
    "    # print(w)\n",
    "    # print(h)\n",
    "    if depth != 16:\n",
    "        print(depth)\n",
    "    bitmap_prop_file = open(\"IMAGENES/\"+\"untitled\"+str(i)+\".PROP\",\"w\")\n",
    "    bitmap_prop_file.write(str(w)+\"\\n\")\n",
    "    bitmap_prop_file.write(str(h)+\"\\n\")\n",
    "    bitmap_prop_file.write(str(palette)+\"\\n\")\n",
    "    bitmap_prop_file.write(str(depth)+\"\\n\")\n",
    "    bitmap_raw_file = open(\"IMAGENES/\"+\"untitled\"+str(i)+\".BITD\",\"wb\")\n",
    "    file.seek(resources[owned[bitmaps[i]][0][0]][1],0)\n",
    "    file.read(8)\n",
    "    bitmap_raw_file.write(file.read(resources[owned[bitmaps[i]][0][0]][2]))\n",
    "    bitmap_prop_file.close()\n",
    "    bitmap_raw_file.close()\n",
    "    #print(resources[owned[bitmaps[i]][0][0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== READING SOUNDS =====\n",
    "\n",
    "for i in range(0, len(sounds)):\n",
    "    snd_file = open('SONIDOS/' + 'test' + str(i) + '.snd_', 'wb')\n",
    "    sample_file = open('SONIDOS/' + 'test' + str(i) + '.sample', 'wb')\n",
    "    snds = [x for x in owned[sounds[i]] if x[1] == ' dns']\n",
    "\n",
    "    file.seek(resources[snds[0][0]][1],0)\n",
    "    file.read(8) # snd_\n",
    "    snd_file.write(file.read(4))\n",
    "    binary_snd_header_size = file.read(4)\n",
    "    snd_header_size, = struct.unpack(\"<I\", binary_snd_header_size)\n",
    "    snd_file.write(binary_snd_header_size)\n",
    "    snd_file.write(file.read(snd_header_size))\n",
    "        \n",
    "    file.read(4)\n",
    "    sample_size, = struct.unpack(\"<I\", file.read(4))\n",
    "    sample_file.write(file.read(sample_size))\n",
    "        \n",
    "    snd_file.close()\n",
    "    sample_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPIRED BY https://github.com/System25/drxtract/blob/master/snd2wav\n",
    "\n",
    "import wave\n",
    "\n",
    "def savewav(name):\n",
    "    \n",
    "    # ===== READING SOUND HEADER =====\n",
    "    \n",
    "    # Opening the header file.\n",
    "    sound_header_file = open(\"SONIDOS/\" + name + \".snd_\", \"rb\")\n",
    "    \n",
    "    # We don't care about the first 50 bytes.\n",
    "    sound_header_file.read(52)\n",
    "    \n",
    "    # The rate seems to be stored here.\n",
    "    rate, = struct.unpack(\">I\", sound_header_file.read(4))\n",
    "    \n",
    "    # The following relation seems to hold.\n",
    "    aux, = struct.unpack(\">I\", sound_header_file.read(4))\n",
    "    bps = 0\n",
    "    if int(aux/rate) == 2:\n",
    "        bps = 16\n",
    "    else:\n",
    "        bps = 8\n",
    "    \n",
    "    # Channels.\n",
    "    channels = 1 # seems to be the case.\n",
    "    \n",
    "    # Closing the header file.\n",
    "    sound_header_file.close()\n",
    "    \n",
    "    # print(name + \" \" + str(rate))\n",
    "    \n",
    "    # ===== READING SOUND SAMPLE =====\n",
    "    \n",
    "    # Managing the raw file\n",
    "    sound_raw_file = open(\"SONIDOS/\" + name + \".sample\", \"rb\")\n",
    "    sound_raw_buffer = sound_raw_file.read()\n",
    "    sound_raw_file.close()\n",
    "    frames_count = len(sound_raw_buffer)\n",
    "    \n",
    "    # Opening the wav file\n",
    "    wav_file = wave.open(\"SONIDOS/\" + name + \".wav\",\"w\")\n",
    "    \n",
    "    # Wav file settings\n",
    "    wav_file.setnchannels(channels)\n",
    "    wav_file.setsampwidth(int(bps/8))\n",
    "    wav_file.setframerate(rate)\n",
    "    \n",
    "    # Writing and closing the wav file\n",
    "    if bps == 16:\n",
    "        for i in range(0, frames_count, 2):\n",
    "            sample =  int(struct.unpack(\">H\", sound_raw_buffer[i:i+2])[0])\n",
    "            data = struct.pack(\"<H\", sample)\n",
    "            wav_file.writeframesraw(data)\n",
    "    else:\n",
    "        wav_file.writeframesraw(sound_raw_buffer)\n",
    "    \n",
    "    wav_file.writeframes(b'')\n",
    "    wav_file.close()\n",
    "    \n",
    "    # Using ffmpeg to generate .mp3 file\n",
    "    os.system(\"ffmpeg -y -i \" + \"SONIDOS/\" + name + \".wav\" + \" -acodec libmp3lame \" + \"SONIDOS/\" + name + \".mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test32 22050\n",
      "test17 22050\n",
      "test54 22050\n",
      "test39 22050\n",
      "test6 22050\n",
      "test14 22050\n",
      "test30 22050\n",
      "test26 22050\n",
      "test18 11025\n",
      "test10 22050\n",
      "test2 11025\n",
      "test31 22050\n",
      "test41 22050\n",
      "test20 22050\n",
      "test25 22050\n",
      "test28 22050\n",
      "test19 11025\n",
      "test23 22050\n",
      "test45 22050\n",
      "test53 11025\n",
      "test5 22050\n",
      "test51 22050\n",
      "test36 22050\n",
      "test34 22050\n",
      "test43 22050\n",
      "test46 22050\n",
      "test50 22050\n",
      "test1 22050\n",
      "test16 11025\n",
      "test27 22050\n",
      "test3 22050\n",
      "test44 22050\n",
      "test38 22050\n",
      "test0 22050\n",
      "test47 22050\n",
      "test11 22050\n",
      "test57 22050\n",
      "test35 22050\n",
      "test33 22050\n",
      "test4 11025\n",
      "test52 22050\n",
      "test15 22050\n",
      "test21 22050\n",
      "test12 22050\n",
      "test48 22050\n",
      "test7 22050\n",
      "test24 22050\n",
      "test49 22050\n",
      "test29 22050\n",
      "test42 22050\n",
      "test56 22050\n",
      "test37 22050\n",
      "test55 22050\n",
      "test40 22050\n",
      "test13 22050\n",
      "test22 22050\n",
      "test8 11025\n",
      "test9 22050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "sounds = os.listdir('SONIDOS')\n",
    "\n",
    "for f in sounds:\n",
    "    if f.endswith(\".sample\"):\n",
    "        name = os.path.splitext(f)[0]\n",
    "        savewav(name)\n",
    "\n",
    "os.system(\"rm SONIDOS/*.snd_\")\n",
    "os.system(\"rm SONIDOS/*.sample\")\n",
    "os.system(\"rm SONIDOS/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE DECOMPRESSION ALGORITHM MOSTLY TAKEN FROM https://github.com/System25/drxtract/blob/master/bitd2bmp\n",
    "\n",
    "import logging\n",
    "\n",
    "def save_16bit_bmp(bmp_width, bmp_height, file, fdata, name):\n",
    "    \n",
    "    bmp_bpp = 16\n",
    "    \n",
    "    # THERE IS A PADDING PROBLEM!!!\n",
    "    padding = (4 - (bmp_width * int(bmp_bpp/8)) % 4) % 4\n",
    "    # print(\"padding \" + str(padding))\n",
    "    \n",
    "    file.write('BM'.encode('ascii'))\n",
    "    hsize = 40\n",
    "    values = (((bmp_width*2)+padding)*bmp_height+hsize+14, # The size of the BMP file in bytes\n",
    "              0, # Reserved\n",
    "              0, # Reserved\n",
    "              (hsize+14) # Data offset\n",
    "             )\n",
    "    s = struct.Struct('<ihhi')\n",
    "    packed_data = s.pack(*values)\n",
    "    file.write(packed_data)\n",
    "\n",
    "    # Write BITMAPINFOHEADER\n",
    "    values = (hsize, # the size of this header (hsize bytes)\n",
    "              bmp_width, # the bitmap width in pixels (signed integer)\n",
    "              bmp_height, # the bitmap height in pixels (signed integer)\n",
    "              1, # the number of color planes (must be 1)\n",
    "              bmp_bpp, # the number of bits per pixel, which is the color depth of the image. Typical values are 1, 4, 8, 16, 24 and 32.\n",
    "              0, # the compression method being used (BI_BITFIELDS)\n",
    "              0, # the image size. This is the size of the raw bitmap data; a dummy 0 can be given for BI_RGB bitmaps.\n",
    "              0, # the horizontal resolution of the image. (pixel per meter, signed integer)\n",
    "              0, # the vertical resolution of the image. (pixel per meter, signed integer)\n",
    "              0, # the number of colors in the color palette, or 0 to default to 2n\n",
    "              0, # the number of important colors used, or 0 when every color is important; generally ignored\n",
    "             )\n",
    "    s = struct.Struct('<iiihhIIIIII')\n",
    "    packed_data = s.pack(*values)\n",
    "    file.write(packed_data)\n",
    "\n",
    "    # get the pixel information\n",
    "    # RLE encoded bytes are:\n",
    "    #   - RLE encoded lower byte\n",
    "    #   - RLE encoded upper byte\n",
    "\n",
    "    w = bmp_width*2\n",
    "    h = bmp_height\n",
    "    \n",
    "    castData = [200 for x in range((w+padding)*bmp_height)]\n",
    "    x = 0\n",
    "    y = bmp_height - 1\n",
    "    idx = 0\n",
    "    \n",
    "    compress = False\n",
    "    \n",
    "    if (len(fdata) == bmp_width*bmp_height*2):\n",
    "        print(name + \" PROBABLY UNCOMPRESSED\")\n",
    "        print(padding)\n",
    "        for i in range(h-1,-1,-1):\n",
    "            for j in range(0,w,2):\n",
    "                castData[i*(w+padding)+j+1] = struct.unpack(\"B\", fdata[idx:idx+1])[0]\n",
    "                idx += 1\n",
    "                castData[i*(w+padding)+j] = struct.unpack(\"B\", fdata[idx:idx+1])[0]\n",
    "                idx += 1\n",
    "    else:\n",
    "        compress = True\n",
    "        vueltas = 0\n",
    "        while (idx < len(fdata)) and (y>=0) and True:\n",
    "            #logging.debug(\"HERE:\"+str(type(fdata)))\n",
    "            val = struct.unpack(\"B\", fdata[idx:idx+1])[0]\n",
    "            if (val & 0x80) != 0:\n",
    "                # RLE encoded\n",
    "                run_length = 257 - val\n",
    "                run_value = struct.unpack(\"B\", fdata[idx+1:idx+2])[0]\n",
    "                idx = idx + 2\n",
    "\n",
    "                # Jump to next byte when necessary\n",
    "                if ((x + run_length) > bmp_width) and (x < bmp_width):\n",
    "                    x = bmp_width\n",
    "\n",
    "                # Jump to next row when necessary\n",
    "                if ((x + run_length) > w):\n",
    "                    x = 0\n",
    "                    y -= 1\n",
    "\n",
    "                for i in range(0, run_length):\n",
    "                    castData[y*(w+padding) + x] = run_value\n",
    "                    x += 1\n",
    "\n",
    "            else:\n",
    "                # Not RLE encoded\n",
    "                run_length = val + 1\n",
    "                idx = idx + 1\n",
    "\n",
    "                # Jump to next byte when necessary\n",
    "                if ((x + run_length) > bmp_width) and (x < bmp_width):\n",
    "                    x = bmp_width\n",
    "\n",
    "                # Jump to next row when necessary\n",
    "                if ((x + run_length) > w):\n",
    "                    x = 0\n",
    "                    y -= 1\n",
    "\n",
    "                for i in range(0, run_length):\n",
    "                    castData[y*(w+padding) + x] = struct.unpack(\"B\", fdata[idx:idx+1])[0]\n",
    "                    idx = idx + 1\n",
    "                    x += 1\n",
    "                    if x >= w:\n",
    "                        x = 0\n",
    "                        y -= 1\n",
    "            vueltas +=1\n",
    "            if vueltas < 0:\n",
    "                break\n",
    "    \n",
    "    #print(y)\n",
    "    #print(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if not ((y == 0 and x == w) or (y == -1 and x == 0)) and compress:\n",
    "        logging.warning(name + \" Probably not properly generated\")\n",
    "    \n",
    "    \n",
    "    # Order lower and upper bytes\n",
    "    castDatamix = [200 for x in range(((bmp_width*2)+padding)*bmp_height)]\n",
    "    \n",
    "    if compress:\n",
    "        w2 = bmp_width*2 + padding\n",
    "        w1 = bmp_width\n",
    "        w0 = 0\n",
    "        for y in range(0, bmp_height):\n",
    "            yw1 = y*w1\n",
    "            yw2 = y*w2\n",
    "            for x in range(0, bmp_width):\n",
    "                castDatamix[yw2 + x*2 + 0] = castData[yw2 + w1 + x]  # Upper\n",
    "                castDatamix[yw2 + x*2 + 1] = castData[yw2 + w0 + x]  # Lower\n",
    "    else:\n",
    "        # print(castData)\n",
    "        castDatamix=castData\n",
    "    \n",
    "    # Write the pixel information\n",
    "    file.write(struct.pack(\"B\"*(((bmp_width)*2+padding)*bmp_height), *castDatamix))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untitled408 PROBABLY UNCOMPRESSED\n",
      "0\n",
      "untitled234 still unsupported\n",
      "untitled205 PROBABLY UNCOMPRESSED\n",
      "2\n",
      "untitled231 still unsupported\n",
      "untitled57 still unsupported\n",
      "untitled278 PROBABLY UNCOMPRESSED\n",
      "0\n",
      "untitled56 still unsupported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:untitled328 Probably not properly generated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untitled229 still unsupported\n",
      "untitled236 still unsupported\n",
      "untitled235 still unsupported\n",
      "untitled393 still unsupported\n",
      "untitled239 still unsupported\n",
      "untitled230 still unsupported\n",
      "untitled50 still unsupported\n",
      "untitled237 still unsupported\n",
      "untitled55 still unsupported\n",
      "untitled58 still unsupported\n",
      "untitled45 still unsupported\n",
      "untitled44 still unsupported\n",
      "untitled232 still unsupported\n",
      "untitled47 still unsupported\n",
      "untitled52 still unsupported\n",
      "untitled51 still unsupported\n",
      "untitled48 still unsupported\n",
      "untitled46 still unsupported\n",
      "untitled53 still unsupported\n",
      "untitled49 still unsupported\n",
      "untitled54 still unsupported\n",
      "untitled228 still unsupported\n",
      "untitled43 still unsupported\n",
      "untitled238 still unsupported\n",
      "untitled233 still unsupported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "images = os.listdir('IMAGENES')\n",
    "\n",
    "for f in images:\n",
    "    if f.endswith(\".BITD\"):\n",
    "        name = os.path.splitext(f)[0]\n",
    "        if (name + \".PROP\" in images) and True:\n",
    "            prop_file = open(\"IMAGENES/\"+name + \".PROP\", 'r')\n",
    "            w = prop_file.readline()\n",
    "            h = prop_file.readline()\n",
    "            p = prop_file.readline()\n",
    "            b = prop_file.readline()\n",
    "            #print(b)\n",
    "            #print(name)\n",
    "\n",
    "            bitd_sample_file = open(\"IMAGENES/\"+f,'rb')\n",
    "            buffer = bitd_sample_file.read()\n",
    "            out = open(\"IMAGENES/\"+name+\".bmp\",'wb')\n",
    "\n",
    "            if int(b) == 16:\n",
    "                save_16bit_bmp(int(w),int(h),out,buffer,name)\n",
    "                out.close()\n",
    "                bitd_sample_file.close()\n",
    "            else:\n",
    "                print(name + \" still unsupported\")\n",
    "        else:\n",
    "            print(\"no properties file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
